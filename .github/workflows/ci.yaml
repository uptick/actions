# Our AIO CI pipeline that can be used for anything and comes with default best practices
# behind caching, slack alerting and more.
# Using this will force us to ensure our projects are all standardized
# TODO:
# - docker file installing/building : Important for us to set best practices for this
# - dependency scanning????

on:
  workflow_call:
    secrets:
      SLACK_TOKEN:
        description: "DEPRECATED"
        required: false
      SLACK_CHANNEL:
        description: "DEPRECATED"
        required: false
      checkout-ssh-key:
        description: "The ssh key if provided; to checkout the repo with"
        required: false

    inputs:
      checkout-ref:
        description: "The branch, tag or SHA to checkout. When empty defaults to default checkout branch"
        type: string
        default: ""
      python-version:
        description: "Version of python to install"
        type: string
        default: "3.10"

      python:
        description: "Install python?"
        type: boolean
        default: false

      # Pip Settings # TODO
      # pip-install:
      #   description: "Run pip install"
      #   type: boolean
      #   default: false

      # pip-install-requirements-path:
      #   description: "Set the path to the requirements file"
      #   type: string
      #   default: "requirements.txt"

      # Poetry Settings
      poetry:
        description: "Install and setup poetry"
        type: boolean
        default: false

      poetry-install:
        description: "Install poetry dependencies (including dev)"
        type: boolean
        default: true

      poetry-install-command:
        description: "Specify a different command; defaults to (poetry install)"
        type: string
        default: "poetry install"

      poetry-version:
        description: "Poetry version to install"
        type: string
        default: "1.8.2"

      pypi-publish:
        description: "Publish to pypi?"
        type: boolean
        default: false

      pypi-repository-url:
        description: "If pypi-publish and pypi-repository-url is set, publish to this pypi repository. Requires id-token: write. For testing use https://test.pypi.org/legacy/"
        type: string
        required: false
        default: "https://upload.pypi.org/legacy/"

      # Node Settings
      node:
        description: "Install node?"
        type: boolean
        default: false

      node-version:
        description: "Version of node to install"
        type: string
        default: "16"

      # PNPM SETTINGS
      pnpm:
        description: "Install and set up pnpm"
        type: boolean
        default: false

      pnpm-install:
        description: "Install pnpm dependencies"
        type: boolean
        default: true

      pnpm-build:
        description: "Run PNPM Build"
        type: boolean
        default: true

      # Slack error settings # TODO
      slack-on-error:
        description: "DEPRECATED"
        type: boolean
        default: false

      shame-on-error:
        description: "DEPRECATED"
        type: boolean
        default: false

      praise-on-fix:
        description: "DEPRECATED"
        type: boolean
        default: false

      slack-channel:
        description: "DEPRECATED"
        type: string
        default: "devops-test-slack"

      # CI command
      command:
        description: "The primary command to run. Defaults to make ci (but it can also be a bash script)"
        type: string
        default: "make ci"

      # docker settings
      docker-enabled:
        description: "if enabled, build + push a docker image "
        type: boolean
        default: false

      # docker settings
      docker-buildx-enabled:
        description: "if enabled, enables docker buildx"
        type: boolean
        default: false

      docker-context:
        description: "Where to find the Dockerfile"
        type: string
        default: "."

      docker-prefix:
        description: "Image tag to prefix. Eg: {subman}-aed1f13, where subman is the docker-prefix"
        type: string
        default: ""

      docker-tag-latest:
        description: "Tag the image as `latest`"
        type: boolean
        default: false

      docker-tag:
        description: "Manual docker tag to include"
        type: string
        default: ''

      docker-repository:
        description: "Required if specifying docker-enabled. This is the ECR repository. EG:  305686791668.dkr.ecr.ap-southeast-2.amazonaws.com/uptick"
        type: string
        default: ""

      docker-image-platforms:
        description: "A comma separated list of platform to be used for building the docker image"
        type: string
        default: "linux/amd64"

      ecr-type:
        description: "The type of AWS ECR repository to push to public or private"
        type: string
        default: "private"

      # AWS Settings
      aws:
        description: "If enabled set up AWS Credentials"
        type: boolean
        default: false

      aws-region:
        description: "The AWS region to configure the AWS profile with"
        type: string
        default: "ap-southeast-2"

      aws-iam-role-arn:
        description: "AWS IAM Role to assume"
        type: string
        default: "arn:aws:iam::305686791668:role/default-github-actions-ci-role"

      # MISE Settings
      mise:
        description: "If enabled; installs mise"
        type: boolean
        default: false

      mise-install:
        description: "If enabled; runs mise install to install tools"
        type: boolean
        default: false

      mise-cache:
        description: "If enabled; caches mise via github's cache"
        type: boolean
        default: true
      # BUMP Settings
      bump-app:
        description: "App to bump"
        type: string
        default: ""

      debug:
        description: "Dump context"
        type: boolean
        default: false

env:
  PYTHONUNBUFFERED: 1
  DEPLOYMENTS_ACCOUNT_ID: "610829907584"

permissions:
  id-token: write # Required for federated aws oidc
  actions: read
  contents: write # to be able to publish a GitHub release
  issues: write # to be able to comment on released issues
  pull-requests: write # to be able to comment on released pull requests


  # actions: read # What for?
  # pull-requests: write # What for?

jobs:
  ci:
    runs-on: ubuntu-22.04
    steps:
    - name: Checkout Code
      uses: actions/checkout@v3
      with:
        # TODO: Configure fetch-depth?
        fetch-depth: 2
        ref: ${{ inputs.checkout-ref }}
        ssh-key: ${{ secrets.checkout-ssh-key }}

    - name: Dump GitHub context
      if: inputs.debug
      env:
        GITHUB_CONTEXT: ${{ toJson(github) }}
      run: echo "$GITHUB_CONTEXT"

    - name: Set environment variables
      shell: bash
      run: |
        if [[ ${{github.event_name}} != 'pull_request' ]];
        then
          echo "GITHUB_EVENT=push" >> $GITHUB_ENV
          echo "BRANCH_NAME=$(echo ${GITHUB_REF#refs/heads/} )" >> $GITHUB_ENV
          echo "GIT_SHORT_HASH=${{github.sha}}" | cut -c -22  >> $GITHUB_ENV
        else
          echo "GITHUB_EVENT=pull_request" >> $GITHUB_ENV
          echo "BRANCH_NAME=$(echo ${GITHUB_HEAD_REF} )" >> $GITHUB_ENV
          export GIT_HEAD_SHA=${{github.event.pull_request.head.sha}}
          export GIT_SHORT_HASH=$(echo $GIT_HEAD_SHA | cut -c -7)
          echo "GIT_SHORT_HASH=$GIT_SHORT_HASH" >> $GITHUB_ENV
        fi;
        echo "GITHUB_REPOSITORY=${{github.repository}}" >> $GITHUB_ENV
        echo "AWS_SESSION_NAME=${{github.repository}}" | sed 's/\//-/g' >> $GITHUB_ENV
        echo "ALTERNATE_DOCKER_REPOSITORY=${{ inputs.docker-repository }}" | sed "s/^ALTERNATE_DOCKER_REPOSITORY=\([0-9]\{12\}\)/ALTERNATE_DOCKER_REPOSITORY=${{env.DEPLOYMENTS_ACCOUNT_ID}}/g" >> $GITHUB_ENV
        echo "MAIN_ACCOUNT_ID=${{ inputs.docker-repository }}" | sed -n "s/^MAIN_ACCOUNT_ID=\([0-9]\{12\}\).*/MAIN_ACCOUNT_ID=\1/p" >> $GITHUB_ENV
        cat $GITHUB_ENV

    - name: Setup and Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      if: inputs.aws || inputs.docker-enabled || (inputs.bump-app != '')
      with:
        role-to-assume: ${{ inputs.aws-iam-role-arn }}
        role-session-name: ${{ env.AWS_SESSION_NAME}}
        aws-region: ${{ inputs.aws-region }}

    ### Mise
    - uses: jdx/mise-action@v2
      if: inputs.mise
      with:
        install: ${{ inputs.mise-install }} # [default: true] run `mise install`
        cache: ${{ inputs.mise-cache }} # [default: true] cache mise using GitHub's cache
        experimental: true


    ### PYTHON AND POETRY STUFF
    #
    - name: Install Python
      if: inputs.python
      uses: actions/setup-python@v3
      with:
        python-version: ${{ inputs.python-version }}

    - name: Setup and Configure Poetry
      if: inputs.poetry
      run: pip3 install poetry==${{ inputs.poetry-version }}

    - name: Cache Poetry Dependencies
      uses: actions/cache@v3
      if: inputs.poetry
      with:
        path: ~/.cache/pypoetry
        key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
        restore-keys: ${{ runner.os }}-poetry-

    - name: Poetry Install Dependencies
      if: inputs.poetry && inputs.poetry-install
      run: |
        ${{ inputs.poetry-install-command }}

    ##### NODE AND PNPM STUFF
    #
    - name: Install Node
      if: inputs.node
      uses: actions/setup-node@v3
      with:
        node-version: ${{ inputs.node-version }}

    - name: Install PNPM
      if: inputs.pnpm
      uses: pnpm/action-setup@v2.2.4
      with:
        version: next-7

    - name: Get PNPM Cache Directory
      if: inputs.pnpm
      id: pnpm-cache
      shell: bash
      run: |
        echo "pnpm_cache_dir=$(pnpm store path)" >> $GITHUB_OUTPUT

    - name: Setup PNPM Cache
      uses: actions/cache@v3
      if: inputs.pnpm
      with:
        path: ${{ steps.pnpm-cache.outputs.pnpm_cache_dir }}
        key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
        restore-keys: |
          ${{ runner.os }}-pnpm-store-

    - name: Install PNPM Dependencies
      if: inputs.pnpm && inputs.pnpm-install
      shell: bash
      run: |
        pnpm install

    - name: PNPM Build
      if: inputs.pnpm && inputs.pnpm-build
      shell: bash
      run: |
        pnpm build

    - name: Run CI Command
      shell: bash
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        ${{ inputs.command }}

    - name: Set up Docker Buildx
      if: inputs.docker-enabled || inputs.docker-buildx-enabled
      uses: docker/setup-buildx-action@v2
    # Login to multiple repos if not pushing to only the deployments account
    - name: Login to Amazon ECR Private
      if: inputs.docker-enabled
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
      with:
        registry-type: ${{ inputs.ecr-type }}
        registries: "${{ env.MAIN_ACCOUNT_ID == env.DEPLOYMENTS_ACCOUNT_ID && env.MAIN_ACCOUNT_ID || format('{0},{1}', env.MAIN_ACCOUNT_ID, env.DEPLOYMENTS_ACCOUNT_ID) }}"
    # Build and push to the main repo plus an additional repo in deployments account
    # Should be removed after ECR migration is complete
    - name: Build and push image
      id: docker_build_push
      if: inputs.docker-enabled
      uses: docker/build-push-action@v6
      with:
        context: "{{defaultContext}}:${{ inputs.docker-context }}"
        file: Dockerfile
        cache-from: type=gha
        cache-to: type=gha, mode=max
        provenance: false
        platforms: ${{inputs.docker-image-platforms}}
        push: true
        # TODO: refactor the giant tags line into a script
        # Default to just the git short hash. if docker-tag-latest ; also tag as the latest image
        # Uses the format function and various conditions to determine the tags
        # Based on the condition for each place holder 1,2,3,4 the place holder either has a value or ''
        # 1st condition: inputs.docker-prefix is specified => inputs.docker-prefix && format('{0}-', inputs.docker-prefix) => <inputs.docker-repository>:<inputs.docker-prefix>-<env.GIT_SHORT_HASH>
        # 2nd condition: env.GIT_SHORT_HASH exists and is not null => always true => <inputs.docker-repository>:<env.GIT_SHORT_HASH>
        # 3rd condition: inputs.docker-tag-latest is specified inputs.docker-tag-latest && format(',{0}:latest', inputs.docker-repository) => <inputs.docker-repository>:<env.GIT_SHORT_HASH>,<inputs.docker-repository>:latest
        # 4th condition: inputs.docker-tag is specified => inputs.docker-tag && format(',{0}:{1}', inputs.docker-repository, inputs.docker-tag) => <inputs.docker-repository>:<env.GIT_SHORT_HASH>,<inputs.docker-repository>:<inputs.docker-tag>
        # When multiple condition are true and since they have ',' in the format they will be strung together as such (except for the first two conditions they will be strung together in one tag):
        # <inputs.docker-repository>:<inputs.docker-prefix>-<env.GIT_SHORT_HASH>,<inputs.docker-repository>:latest,<inputs.docker-repository>:<inputs.docker-tag>
        tags: |
          ${{ format('{0}:{1}{2}{3}{4}', inputs.docker-repository, inputs.docker-prefix && format('{0}-', inputs.docker-prefix) || '', env.GIT_SHORT_HASH, inputs.docker-tag-latest && format(',{0}:latest', inputs.docker-repository) || '', inputs.docker-tag && format(',{0}:{1}', inputs.docker-repository, inputs.docker-tag) || '') }}
          ${{ inputs.docker-repository != env.ALTERNATE_DOCKER_REPOSITORY && format('{0}:{1}{2}{3}{4}', env.ALTERNATE_DOCKER_REPOSITORY, inputs.docker-prefix && format('{0}-', inputs.docker-prefix) || '', env.GIT_SHORT_HASH, inputs.docker-tag-latest && format(',{0}:latest',env.ALTERNATE_DOCKER_REPOSITORY)|| '', inputs.docker-tag && format(',{0}:{1}',env.ALTERNATE_DOCKER_REPOSITORY, inputs.docker-tag) || '') || '' }}

    # - name: Publish Pypi Package
    #   Disabling publishing because pypi are stupid idiots who force you to download a stupid 30s docker files
    #   just to publish  package. What idiots.
    #   # This step expects a built package to be in the dist/ directory
    #   if: inputs.pypi-publish && github.event_name == 'push' && startsWith(github.ref, 'refs/tags')
    #   uses: pypa/gh-action-pypi-publish@release/v1
    #   with:
    #     repository-url: ${{inputs.pypi-repository-url}}

    - name: Bump Repository
      id: bump_repository
      if: inputs.bump-app != ''
      run: |
        python -c 'import botocore; import requests' || pip install boto3 requests
        python -c '
        import subprocess

        import boto3
        import botocore
        import requests

        token = botocore.signers.generate_presigned_url(
            boto3.client("sts"), "get_caller_identity", HttpMethod="GET"
        )
        jwt_token = requests.post(
            "https://tickforge.onuptick.com/token", data={"username": token}
        ).json()["access_token"]
        headers = {"Authorization": f"Bearer {jwt_token}"}
        default_user = subprocess.check_output(
            "git log -n 1 --pretty=format:%an".split()
        ).decode("utf-8")
        default_email = subprocess.check_output(
            "git log -n 1 --pretty=format:%ae".split()
        ).decode("utf-8")
        data = {"author_name": default_user, "author_email": default_email, "redeploy": False}
        response = requests.post(
            "https://tickforge.onuptick.com/api/workspaces/${{inputs.bump-app}}/bump",
            json=data,
            headers=headers,
        )
        print(response.json())
        response.raise_for_status()
        '
