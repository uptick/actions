# Our AIO CI pipeline that can be used for anything and comes with default best practices
# behind caching, slack alerting and more.
# Using this will force us to ensure our projects are all standardized
# TODO:
# - docker file installing/building : Important for us to set best practices for this
# - dependency scanning????

on:
  workflow_call:
    secrets:
      SLACK_TOKEN:
        description: "DEPRECATED"
        required: false
      SLACK_CHANNEL:
        description: "DEPRECATED"
        required: false
      checkout-ssh-key:
        description: "The ssh key if provided; to checkout the repo with"
        required: false
      SECRET_ENV:
        description: "A secret environment variable to faciliate passing in secrets"
        required: false

    inputs:
      checkout-ref:
        description: "The branch, tag or SHA to checkout. When empty defaults to default checkout branch"
        type: string
        default: ""
      python-version:
        description: "Version of python to install"
        type: string
        default: "3.10"

      python:
        description: "Install python?"
        type: boolean
        default: false

      # Pip Settings # TODO
      # pip-install:
      #   description: "Run pip install"
      #   type: boolean
      #   default: false

      # pip-install-requirements-path:
      #   description: "Set the path to the requirements file"
      #   type: string
      #   default: "requirements.txt"

      # Poetry Settings
      poetry:
        description: "Install and setup poetry"
        type: boolean
        default: false

      poetry-install:
        description: "Install poetry dependencies (including dev)"
        type: boolean
        default: true

      poetry-install-command:
        description: "Specify a different command; defaults to (poetry install)"
        type: string
        default: "poetry install"

      poetry-version:
        description: "Poetry version to install"
        type: string
        default: "1.8.2"

      s3pypi-publish:
        description: "Set to true if you want to build and publish to private s3pypi repo."
        type: boolean
        required: false
        default: false

      s3pypi-bucket:
        description: "s3 bucket name for s3pypi"
        type: string
        required: false
        default: "s3pypi-610829907584-us-east-1" 
      
      pypi-dist:
        description: "Build folder of the pypi package."
        type: string
        required: false
        default: "dist/*" 
      
      # uv settings
      uv:
        description: "Install and set up uv"
        type: boolean
        default: false

      uv-cache:
        description: "Cache uv via github's cache"
        type: boolean
        default: true

      uv-sync:
        description: "Sync uv dependencies"
        type: boolean
        default: true

      uv-sync-command:
        description: "Sync command. Defaults to uv sync. Add --all-extras or whatever here."
        type: string
        default: "uv sync"

      uv-version:
        description: "Version of uv to install"
        type: string
        default: "0.5.0"

      uv-directory:
        description: "Path to run uv within"
        type: string
        default: "."

      # Node Settings
      node:
        description: "Install node?"
        type: boolean
        default: false

      node-version:
        description: "Version of node to install"
        type: string
        default: "16"

      # PNPM SETTINGS
      pnpm:
        description: "Install and set up pnpm"
        type: boolean
        default: false

      pnpm-install:
        description: "Install pnpm dependencies"
        type: boolean
        default: true

      pnpm-build:
        description: "Run PNPM Build"
        type: boolean
        default: true

      # Slack error settings # TODO
      slack-on-error:
        description: "DEPRECATED"
        type: boolean
        default: false

      shame-on-error:
        description: "DEPRECATED"
        type: boolean
        default: false

      praise-on-fix:
        description: "DEPRECATED"
        type: boolean
        default: false

      slack-channel:
        description: "DEPRECATED"
        type: string
        default: "devops-test-slack"

      # CI command
      command:
        description: "The primary command to run. Defaults to make ci (but it can also be a bash script)"
        type: string
        default: "make ci"

      # docker settings
      docker-enabled:
        description: "if enabled, build + push a docker image "
        type: boolean
        default: false

      # docker settings
      docker-buildx-enabled:
        description: "if enabled, enables docker buildx"
        type: boolean
        default: false

      docker-context:
        description: "Where to find the Dockerfile"
        type: string
        default: "."

      docker-prefix:
        description: "Image tag to prefix. Eg: {subman}-aed1f13, where subman is the docker-prefix"
        type: string
        default: ""

      docker-tag-latest:
        description: "Tag the image as `latest`"
        type: boolean
        default: false

      docker-tag:
        description: "Manual docker tag to include"
        type: string
        default: ""

      docker-repository:
        description: "Required if specifying docker-enabled. This is the ECR repository. EG:  305686791668.dkr.ecr.ap-southeast-2.amazonaws.com/uptick"
        type: string
        default: ""

      docker-image-platforms:
        description: "A comma separated list of platform to be used for building the docker image"
        type: string
        default: "linux/amd64,linux/arm64"

      docker-push:
        description: "Whether or not to push docker images"
        type: boolean
        default: true

      docker-build-args:
        description: "A comma separated list of Docker Build arguments"
        required: false
        type: string
        default: "ARG1=value1,ARG2=value2"

      ecr-type:
        description: "The type of AWS ECR repository to push to public or private"
        type: string
        default: "private"

      # AWS Settings
      aws:
        description: "If enabled set up AWS Credentials"
        type: boolean
        default: false

      aws-region:
        description: "The AWS region to configure the AWS profile with"
        type: string
        default: "ap-southeast-2"

      aws-iam-role-arn:
        description: "AWS IAM Role to assume"
        type: string
        default: "arn:aws:iam::610829907584:role/default-github-actions-ci-role"

      # MISE Settings
      mise:
        description: "If enabled; installs mise"
        type: boolean
        default: false

      mise-install:
        description: "If enabled; runs mise install to install tools"
        type: boolean
        default: false

      mise-cache:
        description: "If enabled; caches mise via github's cache"
        type: boolean
        default: true
      # BUMP Settings
      bump-app:
        description: "App to bump"
        type: string
        default: ""

      debug:
        description: "Dump context"
        type: boolean
        default: false

env:
  PYTHONUNBUFFERED: 1
  DEPLOYMENTS_ACCOUNT_ID: "610829907584"

permissions:
  id-token: write # Required for federated aws oidc
  actions: read
  contents: write # to be able to publish a GitHub release
  issues: write # to be able to comment on released issues
  pull-requests: write # to be able to comment on released pull requests

  # actions: read # What for?
  # pull-requests: write # What for?

jobs:
  ci:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout Code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # ratchet:actions/checkout@v5
        with:
          # TODO: Configure fetch-depth?
          fetch-depth: 2
          ref: ${{ inputs.checkout-ref }}
          ssh-key: ${{ secrets.checkout-ssh-key }}

      - name: Dump GitHub context
        if: inputs.debug
        env:
          GITHUB_CONTEXT: ${{ toJson(github) }}
        run: echo "$GITHUB_CONTEXT"

      - name: Set environment variables
        shell: bash
        run: |
          if [[ ${{github.event_name}} != 'pull_request' ]];
          then
            echo "GITHUB_EVENT=push" >> $GITHUB_ENV
            echo "BRANCH_NAME=$(echo ${GITHUB_REF#refs/heads/} )" >> $GITHUB_ENV
            echo "GIT_SHORT_HASH=${{github.sha}}" | cut -c -22  >> $GITHUB_ENV
          else
            echo "GITHUB_EVENT=pull_request" >> $GITHUB_ENV
            echo "BRANCH_NAME=$(echo ${GITHUB_HEAD_REF} )" >> $GITHUB_ENV
            export GIT_HEAD_SHA=${{github.event.pull_request.head.sha}}
            export GIT_SHORT_HASH=$(echo $GIT_HEAD_SHA | cut -c -7)
            echo "GIT_SHORT_HASH=$GIT_SHORT_HASH" >> $GITHUB_ENV
          fi;
          echo "GITHUB_REPOSITORY=${{github.repository}}" >> $GITHUB_ENV
          echo "AWS_SESSION_NAME=${{github.repository}}" | sed 's/\//-/g' >> $GITHUB_ENV
          echo "ALTERNATE_DOCKER_REPOSITORY=${{ inputs.docker-repository }}" | sed "s/^ALTERNATE_DOCKER_REPOSITORY=\([0-9]\{12\}\)/ALTERNATE_DOCKER_REPOSITORY=${{env.DEPLOYMENTS_ACCOUNT_ID}}/g" >> $GITHUB_ENV
          echo "MAIN_ACCOUNT_ID=${{ inputs.docker-repository }}" | sed -n "s/^MAIN_ACCOUNT_ID=\([0-9]\{12\}\).*/MAIN_ACCOUNT_ID=\1/p" >> $GITHUB_ENV
          cat $GITHUB_ENV

      - name: Setup and Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@7474bc4690e29a8392af63c5b98e7449536d5c3a # ratchet:aws-actions/configure-aws-credentials@v4
        if: inputs.aws || inputs.docker-enabled || (inputs.bump-app != '') || inputs.s3pypi-publish
        with:
          role-to-assume: ${{ inputs.aws-iam-role-arn }}
          role-session-name: ${{ env.AWS_SESSION_NAME}}
          aws-region: ${{ inputs.aws-region }}

      ### Mise
      - uses: jdx/mise-action@c37c93293d6b742fc901e1406b8f764f6fb19dac # v2
        if: inputs.mise
        with:
          install: ${{ inputs.mise-install }} # [default: true] run `mise install`
          cache: ${{ inputs.mise-cache }} # [default: true] cache mise using GitHub's cache
          experimental: true

      ### PYTHON AND POETRY STUFF
      #
      - name: Install Python
        if: inputs.python
        uses: actions/setup-python@3542bca2639a428e1796aaa6a2ffef0c0f575566 # ratchet:actions/setup-python@v3
        with:
          python-version: ${{ inputs.python-version }}

      - name: Setup and Configure Poetry
        if: inputs.poetry
        run: pip3 install poetry==${{ inputs.poetry-version }}

      - name: Cache Poetry Dependencies
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # ratchet:actions/cache@v4
        if: inputs.poetry
        with:
          path: ~/.cache/pypoetry
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: ${{ runner.os }}-poetry-

      - name: Poetry Install Dependencies
        if: inputs.poetry && inputs.poetry-install
        run: |
          ${{ inputs.poetry-install-command }}

      ### uv stuff
      #
      - name: Install uv
        if: inputs.uv
        uses: astral-sh/setup-uv@caf0cab7a618c569241d31dcd442f54681755d39 # v3
        with:
          version: ${{ inputs.uv-version }}
          enable-cache: ${{ inputs.uv-cache }}

      - name: Run uv sync
        if: inputs.uv && inputs.uv-sync
        working-directory: ${{ inputs.uv-directory }}
        run: ${{ inputs.uv-sync-command }}

      ##### NODE AND PNPM STUFF
      #
      - name: Install Node
        if: inputs.node
        uses: actions/setup-node@3235b876344d2a9aa001b8d1453c930bba69e610 # ratchet:actions/setup-node@v3
        with:
          node-version: ${{ inputs.node-version }}

      - name: Install PNPM
        if: inputs.pnpm
        uses: pnpm/action-setup@eae0cfeb286e66ffb5155f1a79b90583a127a68b # v2.4.1
        with:
          version: next-7

      - name: Get PNPM Cache Directory
        if: inputs.pnpm
        id: pnpm-cache
        shell: bash
        run: |
          echo "pnpm_cache_dir=$(pnpm store path)" >> $GITHUB_OUTPUT

      - name: Setup PNPM Cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # ratchet:actions/cache@v4
        if: inputs.pnpm
        with:
          path: ${{ steps.pnpm-cache.outputs.pnpm_cache_dir }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install PNPM Dependencies
        if: inputs.pnpm && inputs.pnpm-install
        shell: bash
        run: |
          pnpm install

      - name: PNPM Build
        if: inputs.pnpm && inputs.pnpm-build
        shell: bash
        run: |
          pnpm build

      - name: Run CI Command
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SECRET_ENV: ${{ secrets.SECRET_ENV }}
        run: |
          ${{ inputs.command }}

      - name: Set up Docker Buildx
        if: inputs.docker-enabled || inputs.docker-buildx-enabled
        uses: docker/setup-buildx-action@885d1462b80bc1c1c7f0b00334ad271f09369c55 # ratchet:docker/setup-buildx-action@v2
      # Login to multiple repos if not pushing to only the deployments account
      - name: Login to Amazon ECR Private
        if: inputs.docker-enabled
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@062b18b96a7aff071d4dc91bc00c4c1a7945b076 # ratchet:aws-actions/amazon-ecr-login@v2
        with:
          registry-type: ${{ inputs.ecr-type }}
          registries: "${{ env.MAIN_ACCOUNT_ID == env.DEPLOYMENTS_ACCOUNT_ID && env.MAIN_ACCOUNT_ID || format('{0},{1}', env.MAIN_ACCOUNT_ID, env.DEPLOYMENTS_ACCOUNT_ID) }}"
      # Build and push to the main repo plus an additional repo in deployments account
      # Should be removed after ECR migration is complete
      - name: Build and push image
        id: docker_build_push
        if: inputs.docker-enabled
        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # ratchet:docker/build-push-action@v6
        with:
          context: "${{ inputs.docker-context }}"
          file: Dockerfile
          cache-from: type=gha
          cache-to: type=gha, mode=max
          provenance: false
          platforms: ${{inputs.docker-image-platforms}}
          build-args: ${{ inputs.docker-build-args }}
          push: ${{inputs.docker-push}}
          # TODO: refactor the giant tags line into a script
          # Default to just the git short hash. if docker-tag-latest ; also tag as the latest image
          # Uses the format function and various conditions to determine the tags
          # Based on the condition for each place holder 1,2,3,4 the place holder either has a value or ''
          # 1st condition: inputs.docker-prefix is specified => inputs.docker-prefix && format('{0}-', inputs.docker-prefix) => <inputs.docker-repository>:<inputs.docker-prefix>-<env.GIT_SHORT_HASH>
          # 2nd condition: env.GIT_SHORT_HASH exists and is not null => always true => <inputs.docker-repository>:<env.GIT_SHORT_HASH>
          # 3rd condition: inputs.docker-tag-latest is specified inputs.docker-tag-latest && format(',{0}:latest', inputs.docker-repository) => <inputs.docker-repository>:<env.GIT_SHORT_HASH>,<inputs.docker-repository>:latest
          # 4th condition: inputs.docker-tag is specified => inputs.docker-tag && format(',{0}:{1}', inputs.docker-repository, inputs.docker-tag) => <inputs.docker-repository>:<env.GIT_SHORT_HASH>,<inputs.docker-repository>:<inputs.docker-tag>
          # When multiple condition are true and since they have ',' in the format they will be strung together as such (except for the first two conditions they will be strung together in one tag):
          # <inputs.docker-repository>:<inputs.docker-prefix>-<env.GIT_SHORT_HASH>,<inputs.docker-repository>:latest,<inputs.docker-repository>:<inputs.docker-tag>
          tags: |
            ${{ format('{0}:{1}{2}{3}{4}', inputs.docker-repository, inputs.docker-prefix && format('{0}-', inputs.docker-prefix) || '', env.GIT_SHORT_HASH, inputs.docker-tag-latest && format(',{0}:latest', inputs.docker-repository) || '', inputs.docker-tag && format(',{0}:{1}', inputs.docker-repository, inputs.docker-tag) || '') }}
            ${{ inputs.docker-repository != env.ALTERNATE_DOCKER_REPOSITORY && format('{0}:{1}{2}{3}{4}', env.ALTERNATE_DOCKER_REPOSITORY, inputs.docker-prefix && format('{0}-', inputs.docker-prefix) || '', env.GIT_SHORT_HASH, inputs.docker-tag-latest && format(',{0}:latest',env.ALTERNATE_DOCKER_REPOSITORY)|| '', inputs.docker-tag && format(',{0}:{1}',env.ALTERNATE_DOCKER_REPOSITORY, inputs.docker-tag) || '') || '' }}

      - name: Build and Publish Package to S3Pypi
        if: inputs.s3pypi-publish
        shell: bash
        run: |
          uvx s3pypi@2.0.1 upload ${{inputs.pypi-dist}} --bucket ${{inputs.s3pypi-bucket}}

      - name: Bump Repository
        id: bump_repository
        if: inputs.bump-app != ''
        run: |
          python -c 'import botocore; import requests' || pip install boto3 requests
          python -c '
          import subprocess

          import boto3
          import botocore
          import requests

          token = botocore.signers.generate_presigned_url(
              boto3.client("sts"), "get_caller_identity", HttpMethod="GET"
          )
          jwt_token = requests.post(
              "https://tickforge.onuptick.com/token", data={"username": token}
          ).json()["access_token"]
          headers = {"Authorization": f"Bearer {jwt_token}"}
          default_user = subprocess.check_output(
              "git log -n 1 --pretty=format:%an".split()
          ).decode("utf-8")
          default_email = subprocess.check_output(
              "git log -n 1 --pretty=format:%ae".split()
          ).decode("utf-8")
          data = {"author_name": default_user, "author_email": default_email, "redeploy": False}
          response = requests.post(
              "https://tickforge.onuptick.com/api/workspaces/${{inputs.bump-app}}/bump",
              json=data,
              headers=headers,
          )
          print(response.json())
          response.raise_for_status()
          '
